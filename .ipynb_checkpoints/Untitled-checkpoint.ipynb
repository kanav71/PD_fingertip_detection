{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80350e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from visualize import visualize\n",
    "from preprocess.datagen import label_generator, my_label_gen\n",
    "from preprocess.augmentation import rotation, translate, crop, flip_horizontal, flip_vertical, noise, salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5292b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    191.169475\n",
      "Name: new_finger_x, dtype: float64\n",
      "[36, 65, 41, 73]\n"
     ]
    }
   ],
   "source": [
    "##checking error of augmentation after using floating keypoints\n",
    "train_directory = 'C:/Users/Kanav/Documents/Dissertation/Parkinsons_Disease/Codes/Fingertip-Mixed-Reality/Dataset/Train/' \n",
    "valid_directory = 'C:/Users/Kanav/Documents/Dissertation/Parkinsons_Disease/Codes/Fingertip-Mixed-Reality/Dataset/Valid/'\n",
    "label_directory = 'C:/Users/Kanav/Documents/Dissertation/Parkinsons_Disease/Codes/Fingertip-Mixed-Reality/Dataset/label/'\n",
    "\n",
    "labels_data = pd.read_csv(label_directory + \"combined_labels_v3_cleaned.csv\")\n",
    "labels_data[\"filename\"] = labels_data[\"video_name\"] + \"@\" + labels_data.seq.str[3:6].astype(int).astype(str)\n",
    "\n",
    "\n",
    "image_name = \"OC01_R_10s_lowfps.mp4@5.jpg\"\n",
    "\n",
    "image = cv2.imread(train_directory + image_name)\n",
    "\n",
    "## Resizing the image to a square dimension - Kanav\n",
    "old_size = image.shape[:2]\n",
    "desired_size = max(old_size)\n",
    "ratio = float(desired_size)/max(old_size)\n",
    "new_size = tuple([int(x*ratio) for x in old_size])\n",
    "new_size\n",
    "delta_w = desired_size - new_size[1]\n",
    "delta_h = desired_size - new_size[0]\n",
    "top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "color = [0,0,0]\n",
    "image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "value=color)\n",
    "\n",
    "#resizing image as per model requirements - change this when you try some other size - Kanav        \n",
    "image = cv2.resize(image, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Initialize frame counter - kanav - may not be needed now\n",
    "#cnt = 0 \n",
    "filename = image_name.split(\".jpg\")[0]\n",
    "#file_index = int(image_name.split(\"@\")[1].split(\".\")[0])\n",
    "#temp_labels = labels_data[labels_data[\"filename\"] == filename]\n",
    "\n",
    "keypoints = []\n",
    "\n",
    "#adjusting the width labels as per new image dimensions of a square\n",
    "x1 = (labels_data[labels_data[\"filename\"] == filename][\"new_finger_x\"]) + left\n",
    "y1 = (labels_data[labels_data[\"filename\"] == filename][\"new_finger_y\"]) + top\n",
    "x2 = (labels_data[labels_data[\"filename\"] == filename][\"new_thumb_x\"]) + left\n",
    "y2 = (labels_data[labels_data[\"filename\"] == filename][\"new_thumb_y\"]) + top\n",
    "\n",
    "aa = (labels_data[labels_data[\"filename\"] == filename][\"new_finger_x\"])\n",
    "#adjusting labels as per dimension of reduced size for model\n",
    "x1 = int(x1*128/(max(old_size)) )\n",
    "y1 = int(y1*128/(max(old_size)) )\n",
    "x2 = int(x2*128/(max(old_size)) )\n",
    "y2 = int(y2*128/(max(old_size)) )\n",
    "\n",
    "keypoints.append(x1)\n",
    "keypoints.append(y1)\n",
    "keypoints.append(x2)\n",
    "keypoints.append(y2)\n",
    "\n",
    "print(aa)\n",
    "print(keypoints)\n",
    "\n",
    "# # 1.0 Original Image\n",
    "# x_batch.append(image)\n",
    "# y_batch_key.append(keypoints)\n",
    "# # visualize(image, keypoints)\n",
    "\n",
    "# \"\"\" Augmentation \"\"\"\n",
    "# # 2.0 Flip\n",
    "# im_flip, k_flip = flip_horizontal(image, keypoints)\n",
    "# x_batch.append(im_flip)\n",
    "# y_batch_key.append(k_flip)\n",
    "# # visualize(im_flip, k_flip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c8b98ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191.16947549999998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels_data.loc[labels_data[\"filename\"] == filename,\"new_finger_x\"]).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9779b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189.4350875"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a7fa629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    36.0\n",
       "Name: new_finger_x, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6804c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = []\n",
    "y_batch_key = []\n",
    "# 1.0 Original Image\n",
    "x_batch.append(image)\n",
    "y_batch_key.append(keypoints)\n",
    "# visualize(image, keypoints)\n",
    "\n",
    "\"\"\" Augmentation \"\"\"\n",
    "# 2.0 Flip\n",
    "im_flip, k_flip = flip_horizontal(image, keypoints)\n",
    "x_batch.append(im_flip)\n",
    "y_batch_key.append(k_flip)\n",
    "# visualize(im_flip, k_flip)\n",
    "\n",
    "# 3.0 Original + rotation\n",
    "im, k = rotation(image, keypoints)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 4.0 Flip + rotation\n",
    "im, k = rotation(im_flip, k_flip)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 5.0 Original + translate\n",
    "im, k = translate(image, keypoints)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 6.0 Flip + translate\n",
    "im, k = translate(im_flip, k_flip)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 7.0 Original + crop\n",
    "im, k = crop(image, keypoints)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 8.0 Flip + crop\n",
    "im, k = crop(im_flip, k_flip)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 9.0 Original + noise\n",
    "im, k = noise(image, keypoints)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 10.0 Flip + noise\n",
    "im, k = noise(im_flip, k_flip)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 11.0 Original + salt\n",
    "im, k = salt(image, keypoints)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 12.0 Flip + salt\n",
    "im, k = salt(im_flip, k_flip)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 13.0 Original + flip vertical\n",
    "im, k = flip_vertical(image, keypoints)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 14.0 Flip + flip vertical\n",
    "im, k = flip_vertical(im_flip, k_flip)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 15.0 Original + rotate + translate\n",
    "im, k = rotation(image, keypoints)\n",
    "im, k = translate(im, k)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 16.0 Flip + rotate + translate\n",
    "im, k = rotation(im_flip, k_flip)\n",
    "im, k = translate(im, k)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 17.0 Original + noise + translate\n",
    "im, k = noise(image, keypoints)\n",
    "im, k = translate(im, k)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 18.0 Flip + noise + translate\n",
    "im, k = noise(im_flip, k_flip)\n",
    "im, k = translate(im, k)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 19.0 Original + crop + translate\n",
    "im, k = crop(image, keypoints)\n",
    "im, k = translate(im, k)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "# 20.0 Flip + crop + translate\n",
    "im, k = crop(im_flip, k_flip)\n",
    "im, k = translate(im, k)\n",
    "x_batch.append(im)\n",
    "y_batch_key.append(k)\n",
    "# visualize(im, k)\n",
    "\n",
    "x_batch = np.asarray(x_batch)\n",
    "x_batch = x_batch.astype('float32')\n",
    "x_batch = x_batch / 255.\n",
    "\n",
    "y_batch_key = np.asarray(y_batch_key)\n",
    "y_batch_key = y_batch_key.astype('float32')\n",
    "y_batch_key = y_batch_key / 128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52c3c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28125   , 0.5078125 , 0.3203125 , 0.5703125 ],\n",
       "       [0.71875   , 0.5078125 , 0.6796875 , 0.5703125 ],\n",
       "       [0.45347747, 0.51970625, 0.4713771 , 0.52761865],\n",
       "       [0.44004056, 0.25948036, 0.5236935 , 0.29988298],\n",
       "       [0.23125   , 0.4178125 , 0.2703125 , 0.4803125 ],\n",
       "       [0.80875003, 0.4778125 , 0.76968753, 0.5403125 ],\n",
       "       [0.24044451, 0.5077163 , 0.27233404, 0.56944686],\n",
       "       [0.7183385 , 0.5039154 , 0.6726915 , 0.56656253],\n",
       "       [0.6611481 , 0.47549623, 0.62595004, 0.40629876],\n",
       "       [0.723273  , 0.47000077, 0.69698966, 0.539474  ],\n",
       "       [0.419113  , 0.45886675, 0.42071503, 0.48937973],\n",
       "       [0.48032224, 0.44861597, 0.49862084, 0.45151594],\n",
       "       [0.6040231 , 0.51794225, 0.56568974, 0.5391372 ],\n",
       "       [0.38085777, 0.52110195, 0.4064349 , 0.5523683 ],\n",
       "       [0.30963928, 0.58809334, 0.35745233, 0.5940843 ],\n",
       "       [0.48899233, 0.68263596, 0.4691197 , 0.6173856 ],\n",
       "       [0.4875001 , 0.26235807, 0.44057208, 0.32211173],\n",
       "       [0.49868613, 0.34354523, 0.5512081 , 0.39687422],\n",
       "       [0.26050442, 0.4877521 , 0.28404367, 0.549769  ],\n",
       "       [0.7854179 , 0.43109336, 0.7625647 , 0.49859223]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6e6c505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc7a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c537c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cfef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., 50., 14., 13.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = [73,34,23,21]\n",
    "pr = [80,82,35,32]\n",
    "kk = abs(np.array(gt)-np.array(pr))\n",
    "zz = kk + np.ones([1,4]) + np.ones([1,4])\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b267e660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9., 50., 14., 13.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
